{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca396be9",
   "metadata": {},
   "source": [
    "## 1. XOR 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7795842",
   "metadata": {},
   "source": [
    "#### (1) OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0979ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [1]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0687464",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143ceec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.356341  ]\n",
      " [0.92209053]\n",
      " [0.9236759 ]\n",
      " [0.9961498 ]\n",
      " [0.8832964 ]\n",
      " [0.9939922 ]\n",
      " [0.99385774]\n",
      " [0.99971735]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(1000):\n",
    "    _, h, p, a = sess.run([train, hypot, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "\n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3af80a",
   "metadata": {},
   "source": [
    "#### (2) AND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd20e954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.01015344]\n",
      " [0.04852104]\n",
      " [0.04406434]\n",
      " [0.18643898]\n",
      " [0.04382184]\n",
      " [0.17077985]\n",
      " [0.18556502]\n",
      " [0.50590295]]\n",
      "예측 :  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [0], [0], [0], [0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(1000):\n",
    "    _, h, p, a = sess.run([train, hypot, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "\n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1a2b9",
   "metadata": {},
   "source": [
    "#### (3) XOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "894ef431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.7500023]\n",
      " [0.7500012]\n",
      " [0.7500012]\n",
      " [0.75     ]\n",
      " [0.7500012]\n",
      " [0.75     ]\n",
      " [0.75     ]\n",
      " [0.7499988]]\n",
      "예측 :  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 :  0.75\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), tf.float32, name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a = sess.run([train, hypot, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "\n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98cc28",
   "metadata": {},
   "source": [
    "#### (4) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba1c4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0ea1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]]\n",
    "\n",
    "y = [0, 1, 1, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b094ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=100).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d3d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "examples = [[0, 0, 0], [1, 1, 1], [0, 1, 0], [1, 0, 0], [1, 1, 0]]\n",
    "exam_label = [0, 0, 1, 1, 1]\n",
    "\n",
    "result = clf.predict(examples)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41b824ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(exam_label, result)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9aec40",
   "metadata": {},
   "source": [
    "#### (5) 딥러닝을 이용한 XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4d26885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.00991341]\n",
      " [0.99542695]\n",
      " [0.99704576]\n",
      " [0.9924141 ]\n",
      " [0.9978443 ]\n",
      " [0.9902837 ]\n",
      " [0.990001  ]\n",
      " [0.02831692]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "# 첫번째 레이어\n",
    "W1 = tf.Variable(tf.random_normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), tf.float32, name=\"bias1\")\n",
    "hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# 두번째 레이어\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias2\")\n",
    "hypot2 = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot2) + (1 - y) * tf.log(1 - hypot2))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a = sess.run([train, hypot2, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "\n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f00952",
   "metadata": {},
   "source": [
    "#### (6) Deep & Wide\n",
    "\n",
    "+ Deep : 6개의 hidden layer 추가\n",
    "+ Wide : 각 계층의 입출력 갯수는 50개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5beec973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[6.9248676e-04]\n",
      " [9.9966913e-01]\n",
      " [9.9960399e-01]\n",
      " [9.9985504e-01]\n",
      " [9.9990618e-01]\n",
      " [9.9983203e-01]\n",
      " [9.9982345e-01]\n",
      " [5.3167343e-04]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "# 첫번째 레이어\n",
    "W1 = tf.Variable(tf.random_normal([3, 50]), tf.float32, name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([50]), tf.float32, name=\"bias1\")\n",
    "hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# 두번째 레이어\n",
    "W2 = tf.Variable(tf.random_normal([50, 50]), tf.float32, name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([50]), tf.float32, name=\"bias2\")\n",
    "hypot2 = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "# 세번째 레이어\n",
    "W3 = tf.Variable(tf.random_normal([50, 50]), tf.float32, name=\"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([50]), tf.float32, name=\"bias3\")\n",
    "hypot3 = tf.sigmoid(tf.matmul(hypot2, W3) + b3)\n",
    "\n",
    "# 네번째 레이어\n",
    "W4 = tf.Variable(tf.random_normal([50, 50]), tf.float32, name=\"weight4\")\n",
    "b4 = tf.Variable(tf.random_normal([50]), tf.float32, name=\"bias4\")\n",
    "hypot4 = tf.sigmoid(tf.matmul(hypot3, W4) + b4)\n",
    "\n",
    "# 다섯번째 레이어\n",
    "W5 = tf.Variable(tf.random_normal([50, 50]), tf.float32, name=\"weight5\")\n",
    "b5 = tf.Variable(tf.random_normal([50]), tf.float32, name=\"bias5\")\n",
    "hypot5 = tf.sigmoid(tf.matmul(hypot4, W5) + b5)\n",
    "\n",
    "# 여섯번째 레이어\n",
    "W6 = tf.Variable(tf.random_normal([50, 1]), tf.float32, name=\"weight6\")\n",
    "b6 = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias6\")\n",
    "hypot = tf.sigmoid(tf.matmul(hypot5, W6) + b6)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a = sess.run([train, hypot, preds, accuracy], feed_dict={X:X_data, y:y_data})\n",
    "\n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3409af",
   "metadata": {},
   "source": [
    "## 2. Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1452fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.01884696]\n",
      " [0.99139476]\n",
      " [0.9973155 ]\n",
      " [0.99036217]\n",
      " [0.9925849 ]\n",
      " [0.98790574]\n",
      " [0.99172634]\n",
      " [0.03093642]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "# 첫번째 레이어\n",
    "W1 = tf.Variable(tf.random_normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([10]), tf.float32, name=\"bias1\")\n",
    "hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# 두번째 레이어\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias2\")\n",
    "hypot2 = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "tf.summary.histogram(\"weight2\", W2)\n",
    "\n",
    "# 비용\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot2) + (1 - y) * tf.log(1 - hypot2))\n",
    "\n",
    "tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "preds = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha01\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot2, preds, accuracy, merged_summary], feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b060309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate tf1\n",
    "# tensorboard --logdir=./log_dir2/alpha01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8dc896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.0130586 ]\n",
      " [0.99186444]\n",
      " [0.99123186]\n",
      " [0.99207604]\n",
      " [0.9871789 ]\n",
      " [0.99247825]\n",
      " [0.9948498 ]\n",
      " [0.03657955]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "# 첫번째 레이어\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "    b1 = tf.Variable(tf.random_normal([10]), tf.float32, name=\"bias1\")\n",
    "    hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"bias1\", b1)\n",
    "    tf.summary.histogram(\"hypot1\", hypot1)\n",
    "\n",
    "# 두번째 레이어\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "    b2 = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias2\")\n",
    "    hypot2 = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias2\", b2)\n",
    "    tf.summary.histogram(\"hypot2\", hypot2)\n",
    "\n",
    "# 비용\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(y * tf.log(hypot2) + (1 - y) * tf.log(1 - hypot2))\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    preds = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha01\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot2, preds, accuracy, merged_summary], feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "092a3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.3775971 ]\n",
      " [0.8221923 ]\n",
      " [0.842606  ]\n",
      " [0.8229219 ]\n",
      " [0.8317431 ]\n",
      " [0.83234143]\n",
      " [0.8286257 ]\n",
      " [0.64307797]]\n",
      "예측 :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "정확도 :  0.875\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 1, 0], \n",
    "                  [1, 0, 1], [1, 1, 1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.array([[0], [1], [1], [1], [1], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[8, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[8, 1])\n",
    "\n",
    "# 첫번째 레이어\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([3, 10]), tf.float32, name=\"weight1\")\n",
    "    b1 = tf.Variable(tf.random_normal([10]), tf.float32, name=\"bias1\")\n",
    "    hypot1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"bias1\", b1)\n",
    "    tf.summary.histogram(\"hypot1\", hypot1)\n",
    "\n",
    "# 두번째 레이어\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([10, 1]), tf.float32, name=\"weight2\")\n",
    "    b2 = tf.Variable(tf.random_normal([1]), tf.float32, name=\"bias2\")\n",
    "    hypot2 = tf.sigmoid(tf.matmul(hypot1, W2) + b2)\n",
    "\n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias2\", b2)\n",
    "    tf.summary.histogram(\"hypot2\", hypot2)\n",
    "\n",
    "# 비용\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(y * tf.log(hypot2) + (1 - y) * tf.log(1 - hypot2))\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    preds = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, y), dtype=tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"log_dir2/alpha001\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for step in range(10000):\n",
    "    _, h, p, a, m = sess.run([train, hypot2, preds, accuracy, merged_summary], feed_dict={X:X_data, y:y_data})\n",
    "    writer.add_summary(m, global_step=step)\n",
    "    \n",
    "print(\"가설 : \", h)\n",
    "print(\"예측 : \", p)\n",
    "print(\"정확도 : \", a)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate tf1\n",
    "# tensorboard --logdir=./log_dir2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6001cf",
   "metadata": {},
   "source": [
    "## 3.ReLU : Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bff2d830",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-84fb6f4620c0>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777)\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b76e271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000159F6D0C1C8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000159F6D977C8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000159F6D31AC8>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f02450",
   "metadata": {},
   "source": [
    "#### (1) 첫번째 모델 구축 : 성능 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a187021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 가설\n",
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "# 비용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb879587",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(hypot, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d71a94f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1     cost :  4.135447265451607\n",
      "epoch :  2     cost :  1.5869419741630553\n",
      "epoch :  3     cost :  1.182617087797685\n",
      "epoch :  4     cost :  1.003619313348424\n",
      "epoch :  5     cost :  0.8976370496099654\n",
      "epoch :  6     cost :  0.8256522349877795\n",
      "epoch :  7     cost :  0.7729123883897607\n",
      "epoch :  8     cost :  0.7308847432786768\n",
      "epoch :  9     cost :  0.6968144714832308\n",
      "epoch :  10     cost :  0.6689749403433374\n",
      "epoch :  11     cost :  0.6447953572056511\n",
      "epoch :  12     cost :  0.6240677540952508\n",
      "epoch :  13     cost :  0.6056649539687415\n",
      "epoch :  14     cost :  0.5896029706434771\n",
      "epoch :  15     cost :  0.5749336985024538\n",
      "epoch :  16     cost :  0.5617937649921936\n",
      "epoch :  17     cost :  0.549875035340136\n",
      "epoch :  18     cost :  0.5388135266304015\n",
      "epoch :  19     cost :  0.5289312875270852\n",
      "epoch :  20     cost :  0.519793087677522\n",
      "epoch :  21     cost :  0.511130421920256\n",
      "epoch :  22     cost :  0.503208843415434\n",
      "epoch :  23     cost :  0.49567299739880977\n",
      "epoch :  24     cost :  0.4886559177528725\n",
      "epoch :  25     cost :  0.4818681916865437\n",
      "epoch :  26     cost :  0.47568358220837315\n",
      "epoch :  27     cost :  0.47021277053789656\n",
      "epoch :  28     cost :  0.4646262687444686\n",
      "epoch :  29     cost :  0.4593471298434516\n",
      "epoch :  30     cost :  0.45449115411801777\n",
      "epoch :  31     cost :  0.44947362385012873\n",
      "epoch :  32     cost :  0.44496151951226304\n",
      "epoch :  33     cost :  0.4408050770651205\n",
      "epoch :  34     cost :  0.43653736976060004\n",
      "epoch :  35     cost :  0.4327045485106385\n",
      "epoch :  36     cost :  0.4291265054724431\n",
      "epoch :  37     cost :  0.4252514217658476\n",
      "epoch :  38     cost :  0.42170992948792185\n",
      "epoch :  39     cost :  0.4184649176489225\n",
      "epoch :  40     cost :  0.4153169945695182\n",
      "epoch :  41     cost :  0.41215936140580606\n",
      "epoch :  42     cost :  0.40893281725319974\n",
      "epoch :  43     cost :  0.4062795765291561\n",
      "epoch :  44     cost :  0.4037284049662676\n",
      "epoch :  45     cost :  0.4008297018029472\n",
      "epoch :  46     cost :  0.3982912491126493\n",
      "epoch :  47     cost :  0.39570344897833754\n",
      "epoch :  48     cost :  0.39333025715567854\n",
      "epoch :  49     cost :  0.3907562802596525\n",
      "epoch :  50     cost :  0.3885080193931404\n",
      "훈련 종료\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"epoch : \", (epoch+1), \"    cost : \", avg_cost)\n",
    "\n",
    "print(\"훈련 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "813df2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9022\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42e335",
   "metadata": {},
   "source": [
    "#### (2) 딥러닝으로 모델 구현 : 성능 87%\n",
    "\n",
    "+ Deep : 레이어는 7개 추가\n",
    "+ Wide : 계층간 입출력 갯수는 256개 \n",
    "+ activation function : relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89c2a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1     cost :  2.355946045355364\n",
      "epoch :  2     cost :  1.3766340225393128\n",
      "epoch :  3     cost :  1.1440655055913063\n",
      "epoch :  4     cost :  1.060302068536932\n",
      "epoch :  5     cost :  0.9224149131774902\n",
      "epoch :  6     cost :  0.886016829230568\n",
      "epoch :  7     cost :  0.8647548844597556\n",
      "epoch :  8     cost :  0.8457356786727902\n",
      "epoch :  9     cost :  0.7960295952450152\n",
      "epoch :  10     cost :  0.7752157070419999\n",
      "epoch :  11     cost :  0.7842601362141695\n",
      "epoch :  12     cost :  0.7064964957670727\n",
      "epoch :  13     cost :  0.6593193799799141\n",
      "epoch :  14     cost :  0.6537498732046648\n",
      "epoch :  15     cost :  0.6239464817263864\n",
      "epoch :  16     cost :  0.596589250347831\n",
      "epoch :  17     cost :  0.5767506276477468\n",
      "epoch :  18     cost :  0.578355887152932\n",
      "epoch :  19     cost :  0.5819878244400025\n",
      "epoch :  20     cost :  0.5676137389919975\n",
      "epoch :  21     cost :  0.5470047712326048\n",
      "epoch :  22     cost :  0.5356326585466205\n",
      "epoch :  23     cost :  0.5292718329212879\n",
      "epoch :  24     cost :  0.5081877205588601\n",
      "epoch :  25     cost :  0.5302784890478307\n",
      "epoch :  26     cost :  0.5287949249961161\n",
      "epoch :  27     cost :  0.5184373804655945\n",
      "epoch :  28     cost :  0.5004031653837726\n",
      "epoch :  29     cost :  0.48842575994404863\n",
      "epoch :  30     cost :  0.4689182704145257\n",
      "epoch :  31     cost :  0.4666562403332107\n",
      "epoch :  32     cost :  0.46902438705617727\n",
      "epoch :  33     cost :  0.46130780631845647\n",
      "epoch :  34     cost :  0.4799302075125957\n",
      "epoch :  35     cost :  0.4518595658649098\n",
      "epoch :  36     cost :  0.44232712897387405\n",
      "epoch :  37     cost :  0.43691460035063984\n",
      "epoch :  38     cost :  0.43923051671548313\n",
      "epoch :  39     cost :  0.42549692587419\n",
      "epoch :  40     cost :  0.4231010375239632\n",
      "epoch :  41     cost :  0.41151817879893543\n",
      "epoch :  42     cost :  0.40850952191786355\n",
      "epoch :  43     cost :  0.4047662008892407\n",
      "epoch :  44     cost :  0.399515775983984\n",
      "epoch :  45     cost :  0.40280252689664986\n",
      "epoch :  46     cost :  0.40208962104537255\n",
      "epoch :  47     cost :  0.39532278093424694\n",
      "epoch :  48     cost :  0.39143713756041093\n",
      "epoch :  49     cost :  0.37885542159730734\n",
      "epoch :  50     cost :  0.386658127795566\n",
      "훈련 종료\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "logit1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logit1)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "logit2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logit2)\n",
    "\n",
    "# Layer3\n",
    "W3 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "logit3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.sigmoid(logit3)\n",
    "\n",
    "# Layer4\n",
    "W4 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b4 = tf.Variable(tf.random_normal([256]))\n",
    "logit4 = tf.matmul(layer3, W4) + b4\n",
    "layer4 = tf.nn.sigmoid(logit4)\n",
    "\n",
    "# Layer5\n",
    "W5 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b5 = tf.Variable(tf.random_normal([256]))\n",
    "logit5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.sigmoid(logit5)\n",
    "\n",
    "# Layer6\n",
    "W6 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b6 = tf.Variable(tf.random_normal([256]))\n",
    "logit6 = tf.matmul(layer5, W6) + b6\n",
    "layer6 = tf.nn.sigmoid(logit6)\n",
    "\n",
    "# Layer7\n",
    "W7 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b7 = tf.Variable(tf.random_normal([10]))\n",
    "logit = tf.matmul(layer6, W7) + b7\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "# 비용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "correct = tf.equal(tf.argmax(hypot, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"epoch : \", (epoch+1), \"    cost : \", avg_cost)\n",
    "\n",
    "print(\"훈련 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99ee9f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.8773\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435b3f0",
   "metadata": {},
   "source": [
    "#### (3) Xavier 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19cb6835",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "epoch :  1     cost :  2.32644468567588\n",
      "epoch :  2     cost :  2.3148323293165753\n",
      "epoch :  3     cost :  2.3142830328507857\n",
      "epoch :  4     cost :  2.313605356216429\n",
      "epoch :  5     cost :  2.311685859506783\n",
      "epoch :  6     cost :  2.3102979772741157\n",
      "epoch :  7     cost :  2.3098446594585065\n",
      "epoch :  8     cost :  2.3083860648762085\n",
      "epoch :  9     cost :  2.3066703761707665\n",
      "epoch :  10     cost :  2.3052124404907244\n",
      "epoch :  11     cost :  2.3027604519237186\n",
      "epoch :  12     cost :  2.2955549014698384\n",
      "epoch :  13     cost :  2.2097806679118754\n",
      "epoch :  14     cost :  1.7824292911182744\n",
      "epoch :  15     cost :  1.6039379839463679\n",
      "epoch :  16     cost :  1.457147263180124\n",
      "epoch :  17     cost :  1.2518397014791314\n",
      "epoch :  18     cost :  0.9989251529086725\n",
      "epoch :  19     cost :  0.8220943515950981\n",
      "epoch :  20     cost :  0.6721412260965873\n",
      "epoch :  21     cost :  0.5567974276976153\n",
      "epoch :  22     cost :  0.48889118844812585\n",
      "epoch :  23     cost :  0.4198135591637002\n",
      "epoch :  24     cost :  0.36571484143083766\n",
      "epoch :  25     cost :  0.32008008073676725\n",
      "epoch :  26     cost :  0.29269226225939665\n",
      "epoch :  27     cost :  0.261139041022821\n",
      "epoch :  28     cost :  0.23259234664115033\n",
      "epoch :  29     cost :  0.22003757184202008\n",
      "epoch :  30     cost :  0.18945236593484882\n",
      "epoch :  31     cost :  0.20126736426895325\n",
      "epoch :  32     cost :  0.16868764698505398\n",
      "epoch :  33     cost :  0.14627685847607536\n",
      "epoch :  34     cost :  0.1454118793796408\n",
      "epoch :  35     cost :  0.12424552947282792\n",
      "epoch :  36     cost :  0.11429192540320496\n",
      "epoch :  37     cost :  0.11259909793734556\n",
      "epoch :  38     cost :  0.09805428954010666\n",
      "epoch :  39     cost :  0.09161152988672257\n",
      "epoch :  40     cost :  0.08417982309379357\n",
      "epoch :  41     cost :  0.07966724420135668\n",
      "epoch :  42     cost :  0.07607473479753189\n",
      "epoch :  43     cost :  0.07022959237748928\n",
      "epoch :  44     cost :  0.06058919135819781\n",
      "epoch :  45     cost :  0.0565708687935363\n",
      "epoch :  46     cost :  0.051233404915441164\n",
      "epoch :  47     cost :  0.04456240243193778\n",
      "epoch :  48     cost :  0.04204856864261356\n",
      "epoch :  49     cost :  0.037407332574102004\n",
      "epoch :  50     cost :  0.03661500264975161\n",
      "훈련 종료\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# Layer1\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "logit1 = tf.matmul(X, W1) + b1\n",
    "layer1 = tf.nn.relu(logit1)\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "logit2 = tf.matmul(layer1, W2) + b2\n",
    "layer2 = tf.nn.relu(logit2)\n",
    "\n",
    "# Layer3\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "logit3 = tf.matmul(layer2, W3) + b3\n",
    "layer3 = tf.nn.sigmoid(logit3)\n",
    "\n",
    "# Layer4\n",
    "W4 = tf.get_variable(\"W4\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([256]))\n",
    "logit4 = tf.matmul(layer3, W4) + b4\n",
    "layer4 = tf.nn.sigmoid(logit4)\n",
    "\n",
    "# Layer5\n",
    "W5 = tf.get_variable(\"W5\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([256]))\n",
    "logit5 = tf.matmul(layer4, W5) + b5\n",
    "layer5 = tf.nn.sigmoid(logit5)\n",
    "\n",
    "# Layer6\n",
    "W6 = tf.get_variable(\"W6\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([256]))\n",
    "logit6 = tf.matmul(layer5, W6) + b6\n",
    "layer6 = tf.nn.sigmoid(logit6)\n",
    "\n",
    "# Layer7\n",
    "W7 = tf.get_variable(\"W7\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([10]))\n",
    "logit = tf.matmul(layer6, W7) + b7\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "# 비용\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y))\n",
    "\n",
    "# 최소 비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "correct = tf.equal(tf.argmax(hypot, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"epoch : \", (epoch+1), \"    cost : \", avg_cost)\n",
    "\n",
    "print(\"훈련 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1221b8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9644\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687442f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f1116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58e6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf546d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74496656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4db060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239233b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa668bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65db82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf019b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21133981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f58940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c527418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a414b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99984356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869978a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cb2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce09854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
